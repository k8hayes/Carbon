---
title: "R Notebook"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---

# Introduction
3/25/21 -
This is my first pass at coding up a model in JAGS and in R. I've tried to comment each line as thoroughly as possible, I've marked which functions belong to which package and I've included the websites and examples I've found useful. 

## Setting up

There's several packages in R for using BUGS/JAGS (R2winBUGS, rjags, jagsUI, runjags, probably many more). Here I use rjags, only since it's the one that I was able to get a model running in the fastest, not because of any actual insight into which package is actually best. 

```{r setting up}
library(here) # alternative to setting the working directory in each file
library(rjags) # there's several packages in R for using BUGS/JAGS, this is the one I had the most luck with
```

# Data
I'm using a stripped down data file, which only contains the following 4 variables: SITE are the two sites I sampled, TREAT is the number of fires, PLOT is each plot and Biomass is the sum of aboveground biomass (understory and overstory) in grams per meter squared. 

Here's what that looks like:

```{r loading in data}
data <- read.csv(here("data/output/biomass_plot.csv"))

head(data)
summary(data)
```
These plots (N = 50) have burned once, twice or three times within short-intervals. The second plot in this next chunk of code shows that aboveground carbon is much lower in plots that have burned more. 

```{r plot data}
plot(data$Biomass ~ as.factor(data$TREAT))
```

The difference between C in plots that have burned different times also means the data is definitely not normally distributed - it's heavily skewed with high C values in unburned plots and low C values in burned plots.

```{r plot histogram}
hist(data$Biomass) # absolutely not normally distributed
```

# Example GLM
I'm using a gamma distribution and a log link function. I run a quick glm below to compare it with the bayesian model a little bit later, but also because I found it helpful to compare the language used in the base R generalized linear modeling framework with the BUGS language I use lower down. 

I choose a gamma distribution since I'm modeling random variables that are highly-skewed and nonnegative (a plot can't have negative biomass) but also not whole numbers (which prevents using negative binomial or poisson distributions). It's definitely not an ideal fit - see the QQ plot - but it's a first attempt. 

```{r glm }
# example in linear model language
glm.gamma <- glm(data$Biomass ~ data$TREAT, family = Gamma(link = "log"))
summary(glm.gamma)
  # intercept 8.10
  # treatment -0.545

plot(glm.gamma)
```

# JAGS
*Here's where we actually get into the JAGS. *

## Drafting the Model
The following chunk of code writes the model as a named text file into the R working directory. The model is everything between the quotations and is written in the BUGS language, not R, so we write it out as a character vector before throwing it to JAGS. 
```{r model text}
cat(file = "gamma.model.txt","
model {
  # Likelihood data model:
  for (i in 1:N) { # loops over every individual
    linear_predictor[i] <- a + b*x[i]  # deterministic relationship
    # dgamma(shape, rate) in JAGS:
    y[i] ~ dgamma(shape, shape / exp(linear_predictor[i])) # stochastic relationship
  }
  
  # dgamma in R is parameterized by shape and rate parameters, not mean/mode/sd
  
  # Priors:
  a ~ dnorm(0, 0.001) # mean, precision = N(0, 10^4)
  b ~ dnorm(0, 0.001)
  shape ~ dunif(0, 100) # uniform density distribution from 0-100
}
")
```

For now, I'm using priors that are pretty vague, since getting this up and running was the goal. I'm interested in maybe spending some time on this on Monday...

I'm keeping the likelihood data model and the priors very separate in the code itself. Some people write them in the opposite order, this is more intuitive to me. 
## Running the Model
The following code sets up and runs the model - there's a ton of styles for how people code this part online, I tried to synthesize a few approaches I found intuitive. 
```{r running model}
N = 50 # observations here are plots, and there's 50 plots
x = data$TREAT # number of fires
y = data$Biomass # aboveground biomass of over + understory #g/m2

forJags <- list(x = x, # pulls in each value as a list
                y = y,
                N = N)

jagsmodel <- rjags::jags.model(file = "gamma.model.txt", # calls in the model text file
                        data = forJags, # calls in data
                        n.chains = 1,# number of parallel chains for model
                        # inits = not set # can specify optimal initial values 
                                        # will generate automatically if not set
                        n.adapt = 5000) # number of iterations for adaptation # can be 0
                                          # made mine real long
```

This link was useful in thinking about the syntax that goes into jags.model(): https://stackoverflow.com/questions/38701100/how-to-interpret-some-syntax-n-adapt-update-in-jags

# Posteriors
```{r posteriors}
# generate posterior samples, coerces into a list
out <- rjags::coda.samples(jagsmodel, 
                    variable.names=c("a", "b"), # 2 variables from model
                    n.iter=1e5, # increase chain length from default
                    thin=5) # keeps every 5th draw
      # Note - this one takes a hot sec to run
```

```{r checking ouput}
summary(out) # I'm running a lot of iterations right now (150000)
```

Here's a cool bit - the glm above calculated the intercept as 8.1050 and the slope as -0.5459. Here, the mean intercept from the chain was 8.1069 (+/- 0.2027 SD) and the slope was -0.5302 (+/- 0.1025 SD). So, close. 

I don't have this coded up here, but if you bring "n.adapt" in the jags.model down to 5000 or so (reducing the number of iterations), the mean intercept and slope get further from the values produced by the glm. Can run in class if folks are interested. 

## Plotting 

```{r plotting posteriors}
plot(out) # plots the posteriors of the intercept and slope
```

The convergence of both looks relatively good, especially compared to some of the examples Ryan and Ericka showed. It's not perfect through - the density of b is slightly less symmetric than a. Both densities got a lot more symmetric when I bumped up the iterations.  

# Diagnostics 

I ran a few specific diagnostic functions, most of which are from the coda package (loaded in when you load rjags).

## Thinning
The first one is the Raftery and Lewis's diagnostic (https://www.rdocumentation.org/packages/coda/versions/0.19-4/topics/raftery.diag), which calculates the smallest value of thinning interval you could use that would let the thinned chain still function as a markov chain. Using that number, it calculates the required sample size. 

```{r chain length}
coda:: raftery.diag(out) # checks chain length / assess required run length
```
The output is the following:

- Burn-in = length of burn-in
- Total (N) = the required sample size
- Lower bound = minimal sample size based on zero autocorrelation
- Dependence factor = extent to which autocorrelation inflates the required sample size

Here, my sample sizes are 21,420 and 25,005, out of the 150,000 iterations. So about 15% or so. 

According to the function documentation, a dependence factor of greater than 5 can indicate strong autocorrelation, which they attribute to poor choice of starting value, high posterior correlations or a 'sticky' MCMC algorithm (which I don't understand yet).

source: https://www.rdocumentation.org/packages/coda/versions/0.19-4/topics/raftery.diag

## Effective sample size
This next function calculates the effective sample size for estimating the mean, adjusted for autocorrelation. The documentation for this one is a bit vague, so still feeling shakey on what this number actually means. 

source: https://www.rdocumentation.org/packages/coda/versions/0.19-4/topics/effectiveSize
```{r effectsive size}
coda :: effectiveSize(out) # from package coda, assesses independence of drws
```

## Stationarity

A test statistic to check stationarity - under the null hypothesis that the sampled values come from a stationary distribution, the test is first applied to the whole chain, and then 10% increments of the chain are discarded until either the null hypothesis is accepted or 50% of the chain is discarded. 

Note - first impression, this seems like one not to take fully at face value (or at least maybe also use other evaluations of stationarity). 

https://www.rdocumentation.org/packages/coda/versions/0.19-4/topics/heidel.diag
```{r stationarity}
coda :: heidel.diag(out)
```
The halfwidth section of this function calculates a 95% CI for the mean, using the proportion of the chain that passes the stationarity test. Passing the halfwidth test means the length of the sample is deemed long enough to estimate the mean with sufficient accuracy.*

*this language in particular makes me a bit nervous, curious about other people's input

# Links that were useful: 

Handuots from the Analysis of Distribution, abundance and species richness in R and BUGS book (Tommy sent out last week)
https://static1.squarespace.com/static/5709969901dbae3cd4146860/t/59fb57f971c10b5d503778e1/1509644283874/AHM+Book+Vol.+1+Chaps.+3--5.pdf


Fitting a gamma distribution a few different ways
https://seananderson.ca/2014/04/08/gamma-glms/

Common error messages in JAGS
https://www4.stat.ncsu.edu/~bjreich/BSMdata/errors.html

Count models (poisson, negative binomial and zero-inflated) - helps walk through diagnostics
https://georgederpa.github.io/teaching/countModels.html

Syntax for jags.model function
https://stackoverflow.com/questions/38701100/how-to-interpret-some-syntax-n-adapt-update-in-jags

Cool comparison of how coding this stuff up has changed over about a decade
https://www.r-bloggers.com/2020/04/no-excuse-not-to-be-a-bayesian-anymore-2/

